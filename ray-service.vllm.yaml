apiVersion: ray.io/v1
kind: RayService
metadata:
  name: llama-3-8b
spec:
  serveConfigV2: |
    applications:
    - name: llm
      route_prefix: /
      import_path: serve:model
      deployments:
      - name: VLLMDeployment
        num_replicas: 1
        ray_actor_options:
          num_cpus: 8
          # NOTE: num_gpus is set automatically based on TENSOR_PARALLELISM
      runtime_env:
        working_dir: "https://github.com/manikantatarun/kuberay/archive/main.zip"
        pip: ["vllm==0.6.1.post2"]
        env_vars:
          MODEL_ID: "models/Llama-3.2-3B-Instruct"
          TENSOR_PARALLELISM: "2"
          PIPELINE_PARALLELISM: "1"
  rayClusterConfig:
    headGroupSpec:
      rayStartParams:
        dashboard-host: '0.0.0.0'
      template:
        spec:
          affinity: 
            nodeAffinity: 
              requiredDuringSchedulingIgnoredDuringExecution: 
                nodeSelectorTerms: 
                - matchExpressions:
                  - key: purpose 
                    operator: In 
                    values: 
                    - kuberayhead
          containers:
          - name: ray-head
            image: rayproject/ray-ml:2.33.0.914af0-py311
          tolerations:
          - key: "kubernetes.azure.com/scalesetpriority"
            operator: "Equal"
            value: "spot"
            effect: "NoSchedule"

            # resources:
            #   limits:
            #     cpu: "2"
            #     memory: "8Gi"
            #   requests:
            #     cpu: "2"
            #     memory: "8Gi"
            # env:
            # - name: HUGGING_FACE_HUB_TOKEN
            #   valueFrom:
            #     secretKeyRef:
            #       name: hf-secret
            #       key: hf_api_token
    workerGroupSpecs:
    - replicas: 1
      minReplicas: 0
      maxReplicas: 4
      groupName: gpu-group
      rayStartParams: {}
      template:
        spec:
          affinity: 
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution: 
                nodeSelectorTerms: 
                - matchExpressions: 
                  - key: purpose
                    operator: In 
                    values: 
                      - kuberay
          containers:
          - name: llm
            image: rayproject/ray-ml:2.33.0.914af0-py311
            volumeMounts:
            - name: model-volume
              mountPath: /models
            # env:
            # - name: HUGGING_FACE_HUB_TOKEN
            #   valueFrom:
            #     secretKeyRef:
            #       name: hf-secret
            #       key: hf_api_token
            # resources:
            #   limits:
            #     cpu: "8"
            #     memory: "20Gi"
            #     # nvidia.com/gpu: "2"
            #   requests:
            #     cpu: "8"
            #     memory: "20Gi"
            #     # nvidia.com/gpu: "2"
          # Please add the following taints to the GPU node.
          volumes:
          - name: model-volume
            persistentVolumeClaim:
              claimName: guard-model-pvc
          # tolerations:
          #   - key: "nvidia.com/gpu"
          #     operator: "Exists"
          #     effect: "NoSchedule"
